{"cells":[{"cell_type":"markdown","metadata":{},"source":["<h3>Download the Data<h3>"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-05-03 20:44:27--  https://github.com/adrianulbona/osm-parquetizer/releases/download/v1.0.0/osm-parquetizer-1.0.0.jar\n","Resolving github.com (github.com)... 20.26.156.215\n","Connecting to github.com (github.com)|20.26.156.215|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/55342414/e040194a-b7f9-11e6-9006-bdf53f66fb86?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240503T204427Z&X-Amz-Expires=300&X-Amz-Signature=4129f91c4a60425359016dc5e0d9158c0900e646ef50acb028472f93ace5ea5b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=55342414&response-content-disposition=attachment%3B%20filename%3Dosm-parquetizer-1.0.0.jar&response-content-type=application%2Foctet-stream [following]\n","--2024-05-03 20:44:27--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/55342414/e040194a-b7f9-11e6-9006-bdf53f66fb86?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240503%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240503T204427Z&X-Amz-Expires=300&X-Amz-Signature=4129f91c4a60425359016dc5e0d9158c0900e646ef50acb028472f93ace5ea5b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=55342414&response-content-disposition=attachment%3B%20filename%3Dosm-parquetizer-1.0.0.jar&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 43354072 (41M) [application/octet-stream]\n","Saving to: ‘/geodata/osm-parquetizer-1.0.0.jar’\n","\n","osm-parquetizer-1.0 100%[===================>]  41.34M  53.8MB/s    in 0.8s    \n","\n","2024-05-03 20:44:28 (53.8 MB/s) - ‘/geodata/osm-parquetizer-1.0.0.jar’ saved [43354072/43354072]\n","\n"]}],"source":["# get convertor, convert the osm.pbf file into parquet file for Spark\n","# see https://adrianulbona.github.io/2016/12/18/osm-parquetizer.html for more info\n","!wget \"https://github.com/adrianulbona/osm-parquetizer/releases/download/v1.0.0/osm-parquetizer-1.0.0.jar\" -P /geodata"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-05-03 20:44:41--  https://download.geofabrik.de/europe/united-kingdom/england/greater-london-latest.osm.pbf\n","Resolving download.geofabrik.de (download.geofabrik.de)... 65.109.48.72, 65.109.50.43, 2a01:4f9:5a:25c3::2, ...\n","Connecting to download.geofabrik.de (download.geofabrik.de)|65.109.48.72|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 102664579 (98M) [application/octet-stream]\n","Saving to: ‘/geodata/greater-london-latest.osm.pbf’\n","\n","greater-london-late 100%[===================>]  97.91M  30.6MB/s    in 3.4s    \n","\n","2024-05-03 20:44:45 (28.5 MB/s) - ‘/geodata/greater-london-latest.osm.pbf’ saved [102664579/102664579]\n","\n","--2024-05-03 20:44:45--  https://download.geofabrik.de/europe/france/ile-de-france-latest.osm.pbf\n","Resolving download.geofabrik.de (download.geofabrik.de)... 65.109.50.43, 65.109.48.72, 2a01:4f9:5a:25c3::2, ...\n","Connecting to download.geofabrik.de (download.geofabrik.de)|65.109.50.43|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 307875400 (294M) [application/octet-stream]\n","Saving to: ‘/geodata/ile-de-france-latest.osm.pbf’\n","\n","ile-de-france-lates 100%[===================>] 293.61M  15.6MB/s    in 19s     \n","\n","2024-05-03 20:45:04 (15.5 MB/s) - ‘/geodata/ile-de-france-latest.osm.pbf’ saved [307875400/307875400]\n","\n","--2024-05-03 20:45:04--  https://download.geofabrik.de/europe/italy/centro-latest.osm.pbf\n","Resolving download.geofabrik.de (download.geofabrik.de)... 65.109.50.43, 65.109.48.72, 2a01:4f9:5a:25c3::2, ...\n","Connecting to download.geofabrik.de (download.geofabrik.de)|65.109.50.43|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 329698960 (314M) [application/octet-stream]\n","Saving to: ‘/geodata/centro-latest.osm.pbf’\n","\n","centro-latest.osm.p 100%[===================>] 314.42M  13.9MB/s    in 22s     \n","\n","2024-05-03 20:45:27 (14.0 MB/s) - ‘/geodata/centro-latest.osm.pbf’ saved [329698960/329698960]\n","\n","--2024-05-03 20:45:27--  https://download.geofabrik.de/north-america/canada/ontario-latest.osm.pbf\n","Resolving download.geofabrik.de (download.geofabrik.de)... 65.109.48.72, 65.109.50.43, 2a01:4f9:5a:2797::2, ...\n","Connecting to download.geofabrik.de (download.geofabrik.de)|65.109.48.72|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 826791999 (788M) [application/octet-stream]\n","Saving to: ‘/geodata/ontario-latest.osm.pbf’\n","\n","ontario-latest.osm. 100%[===================>] 788.49M  36.7MB/s    in 37s     \n","\n","2024-05-03 20:46:04 (21.6 MB/s) - ‘/geodata/ontario-latest.osm.pbf’ saved [826791999/826791999]\n","\n"]}],"source":["# load the city geodata in osm.pbf file in required city\n","!wget 'https://download.geofabrik.de/europe/united-kingdom/england/greater-london-latest.osm.pbf' -P /geodata\n","!wget 'https://download.geofabrik.de/europe/france/ile-de-france-latest.osm.pbf' -P /geodata\n","!wget 'https://download.geofabrik.de/europe/italy/centro-latest.osm.pbf' -P /geodata\n","!wget 'https://download.geofabrik.de/north-america/canada/ontario-latest.osm.pbf' -P /geodata"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/geodata/osm-parquetizer-1.0.0.jar) to method sun.security.krb5.Config.getInstance()\n","WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","2024-05-03 20:46:51 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:46:51 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:46:51 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n","SLF4J: Defaulting to no-operation (NOP) logger implementation\n","SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n","2024-05-03 20:46:54 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 1000000\n","2024-05-03 20:46:55 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 2000000\n","2024-05-03 20:46:56 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 3000000\n","2024-05-03 20:46:57 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 4000000\n","2024-05-03 20:46:58 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 5000000\n","2024-05-03 20:47:00 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 6000000\n","2024-05-03 20:47:01 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 7000000\n","2024-05-03 20:47:02 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 8000000\n","2024-05-03 20:47:03 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 9000000\n","2024-05-03 20:47:09 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 10000000\n","2024-05-03 20:47:15 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 11000000\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,754,122 > 134,217,728: flushing 5,740,100 records to disk.\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,707,678\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 23,328,924B for [id] INT64: 5,740,100 values, 45,920,800B raw, 23,326,813B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,655,017B for [version] INT32: 5,740,100 values, 2,533,629B raw, 1,654,159B comp, 22 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 116 entries, 464B raw, 116B comp}\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 7,824,415B for [timestamp] INT64: 5,740,100 values, 42,740,721B raw, 7,822,308B comp, 44 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 131,062 entries, 1,048,496B raw, 131,062B comp}\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,508B for [changeset] INT64: 5,740,100 values, 528B raw, 616B comp, 44 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,078B for [uid] INT32: 5,740,100 values, 264B raw, 308B comp, 22 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 902B for [user_sid] BINARY: 5,740,100 values, 264B raw, 308B comp, 22 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,850,730B for [tags, key] BINARY: 6,975,414 values, 3,140,564B raw, 1,849,718B comp, 21 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 2,416 entries, 40,934B raw, 2,416B comp}\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 6,862,394B for [tags, value] BINARY: 6,975,414 values, 21,077,814B raw, 6,861,313B comp, 19 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 54,580 entries, 956,069B raw, 54,580B comp}\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41,952,089B for [latitude] DOUBLE: 5,740,100 values, 45,920,800B raw, 41,949,978B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:46:59 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 45,740,218B for [longitude] DOUBLE: 5,740,100 values, 45,920,800B raw, 45,738,107B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 72,447,489\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 13,857,605B for [id] INT64: 3,426,086 values, 27,408,688B raw, 13,856,310B comp, 27 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 241,357B for [version] INT32: 3,426,086 values, 353,017B raw, 240,813B comp, 14 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 16 entries, 64B raw, 16B comp}\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,133,117B for [timestamp] INT64: 3,426,086 values, 1,462,355B raw, 1,131,848B comp, 27 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 93,919 entries, 751,352B raw, 93,919B comp}\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,539B for [changeset] INT64: 3,426,086 values, 324B raw, 378B comp, 27 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 686B for [uid] INT32: 3,426,086 values, 168B raw, 196B comp, 14 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 574B for [user_sid] BINARY: 3,426,086 values, 168B raw, 196B comp, 14 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 777,342B for [tags, key] BINARY: 3,866,110 values, 1,253,154B raw, 776,901B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,472 entries, 26,355B raw, 1,472B comp}\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,033,737B for [tags, value] BINARY: 3,866,110 values, 5,548,155B raw, 2,033,288B comp, 8 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 27,234 entries, 584,007B raw, 27,234B comp}\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,741,389B for [latitude] DOUBLE: 3,426,086 values, 27,408,688B raw, 24,740,094B comp, 27 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 27,334,606B for [longitude] DOUBLE: 3,426,086 values, 27,408,688B raw, 27,333,311B comp, 27 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 96,746,895\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 7,457,039B for [id] INT64: 1,808,240 values, 14,465,920B raw, 7,456,368B comp, 14 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 790,888B for [version] INT32: 1,808,240 values, 1,039,688B raw, 790,615B comp, 7 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 87 entries, 348B raw, 87B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,001,379B for [timestamp] INT64: 1,808,240 values, 12,916,870B raw, 4,000,710B comp, 14 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 126,077 entries, 1,008,616B raw, 126,077B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 798B for [changeset] INT64: 1,808,240 values, 168B raw, 196B comp, 14 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 343B for [uid] INT32: 1,808,240 values, 84B raw, 98B comp, 7 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 287B for [user_sid] BINARY: 1,808,240 values, 84B raw, 98B comp, 7 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,438,495B for [tags, key] BINARY: 6,061,868 values, 9,333,097B raw, 4,434,687B comp, 77 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 3,287 entries, 58,632B raw, 3,287B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 17,860,216B for [tags, value] BINARY: 6,061,868 values, 65,493,977B raw, 17,855,620B comp, 66 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 43,846 entries, 845,981B raw, 43,846B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,982,402B for [nodes, index] INT32: 13,013,373 values, 19,653,879B raw, 5,980,374B comp, 52 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,819 entries, 7,276B raw, 1,819B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 49,718,693B for [nodes, nodeId] INT64: 13,013,373 values, 105,873,649B raw, 49,713,846B comp, 101 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.ha2024-05-03 20:47:16 INFO  App$MultiEntitySinkObserver:123 - Total entities processed: 11005152\n","doop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 7,590,173\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 133,307B for [id] INT64: 30,725 values, 245,800B raw, 133,260B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 27,119B for [version] INT32: 30,725 values, 33,596B raw, 27,080B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 352 entries, 1,408B raw, 352B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 57,217B for [timestamp] INT64: 30,725 values, 57,164B raw, 57,170B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 17,008 entries, 136,064B raw, 17,008B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 57B for [changeset] INT64: 30,725 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 49B for [uid] INT32: 30,725 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41B for [user_sid] BINARY: 30,725 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 133,682B for [tags, key] BINARY: 188,720 values, 278,981B raw, 133,539B comp, 3 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,183 entries, 17,692B raw, 1,183B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 266,615B for [tags, value] BINARY: 188,720 values, 389,126B raw, 266,430B comp, 3 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 35,892 entries, 889,657B raw, 35,892B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,315,775B for [members, id] INT64: 849,857 values, 6,066,009B raw, 3,315,441B comp, 7 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 95,577 entries, 764,616B raw, 95,577B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 124,444B for [members, role] BINARY: 849,857 values, 209,225B raw, 124,274B comp, 5 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 157 entries, 1,923B raw, 157B comp}\n","May 3, 2024 8:47:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 56,590B for [members, type] BINARY: 849,857 values, 63,640B raw, 56,365B comp, 6 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 3 entries, 27B raw, 3B comp}\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/geodata/osm-parquetizer-1.0.0.jar) to method sun.security.krb5.Config.getInstance()\n","WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","2024-05-03 20:47:17 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:47:17 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:47:17 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n","SLF4J: Defaulting to no-operation (NOP) logger implementation\n","SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n","2024-05-03 20:47:19 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 1000000\n","2024-05-03 20:47:20 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 2000000\n","2024-05-03 20:47:21 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 3000000\n","2024-05-03 20:47:22 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 4000000\n","2024-05-03 20:47:23 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 5000000\n","2024-05-03 20:47:24 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 6000000\n","2024-05-03 20:47:25 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 7000000\n","2024-05-03 20:47:26 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 8000000\n","2024-05-03 20:47:27 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 9000000\n","2024-05-03 20:47:28 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 10000000\n","2024-05-03 20:47:29 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 11000000\n","2024-05-03 20:47:30 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 12000000\n","2024-05-03 20:47:31 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 13000000\n","2024-05-03 20:47:32 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 14000000\n","2024-05-03 20:47:33 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 15000000\n","2024-05-03 20:47:34 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 16000000\n","2024-05-03 20:47:35 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 17000000\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,550,040 > 134,217,728: flushing 6,000,100 records to disk.\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,229,423\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,180,840B for [id] INT64: 6,000,100 values, 48,000,800B raw, 24,178,633B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,199,764B for [version] INT32: 6,000,100 values, 2,270,596B raw, 1,198,867B comp, 23 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 108 entries, 432B raw, 108B comp}\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 8,591,756B for [timestamp] INT64: 6,000,100 values, 45,602,780B raw, 8,589,552B comp, 46 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY, BIT_PACKED], dic { 109,481 entries, 875,848B raw, 109,481B comp}\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,622B for [changeset] INT64: 6,000,100 values, 552B raw, 644B comp, 46 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,127B for [uid] INT32: 6,000,100 values, 276B raw, 322B comp, 23 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 943B for [user_sid] BINARY: 6,000,100 values, 276B raw, 322B comp, 23 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 548,326B for [tags, key] BINARY: 6,258,764 values, 815,787B raw, 548,016B comp, 6 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 1,260 entries, 20,875B raw, 1,260B comp}\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,325,093B for [tags, value] BINARY: 6,258,764 values, 4,690,425B raw, 1,323,989B comp, 12 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY], dic { 38,544 entries, 1,036,049B raw, 38,544B comp}\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 44,852,694B for [latitude] DOUBLE: 6,000,100 values, 48,000,800B raw, 44,850,487B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:24 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 47,720,371B for [longitude] DOUBLE: 6,000,100 values, 48,000,800B raw, 47,718,163B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,563,846 > 134,217,728: flushing 6,140,100 records to disk.\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 128,032,747\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,647,938B for [id] INT64: 6,140,100 values, 49,120,800B raw, 24,645,683B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 712,392B for [version] INT32: 6,140,100 values, 1,489,253B raw, 711,456B comp, 24 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 41 entries, 164B raw, 41B comp}\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 6,806,118B for [timestamp] INT64: 6,140,100 values, 42,137,670B raw, 6,803,871B comp, 47 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY, BIT_PACKED], dic { 130,283 entries, 1,042,264B raw, 130,283B comp}\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,679B for [changeset] INT64: 6,140,100 values, 564B raw, 658B comp, 47 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,176B for [uid] INT32: 6,140,100 values, 288B raw, 336B comp, 24 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 984B for [user_sid] BINARY: 6,140,100 values, 288B raw, 336B comp, 24 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 282,845B for [tags, key] BINARY: 6,298,714 values, 453,610B raw, 282,801B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 919 entries, 15,707B raw, 919B comp}\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 505,758B for [tags, value] BINARY: 6,298,714 values, 632,691B raw, 505,662B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 24,266 entries, 504,584B raw, 24,266B comp}\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 42,438,998B for [latitude] DOUBLE: 6,140,100 values, 49,120,800B raw, 42,436,743B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:30 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 47,093,507B for [longitude] DOUBLE: 6,140,100 values, 49,120,800B raw, 47,091,252B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,396,598 > 134,217,728: flushing 5,720,100 records to disk.\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 120,272,406\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 22,986,782B for [id] INT64: 5,720,100 values, 45,760,800B raw, 22,984,671B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 611,263B for [version] INT32: 5,720,100 values, 1,067,972B raw, 610,405B comp, 22 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 42 entries, 168B raw, 42B comp}\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 6,112,537B for [timestamp] INT64: 5,720,100 values, 35,665,240B raw, 6,110,437B comp, 44 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY, BIT_PACKED], dic { 120,820 entries, 966,560B raw, 120,820B comp}\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,508B for [changeset] INT64: 5,720,100 values, 528B raw, 616B comp, 44 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,078B for [uid] INT32: 5,720,100 values, 264B raw, 308B comp, 22 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 902B for [user_sid] BINARY: 5,720,100 values, 264B raw, 308B comp, 22 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 516,952B for [tags, key] BINARY: 6,073,676 values, 933,923B raw, 516,889B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 1,166 entries, 19,787B raw, 1,166B comp}\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 752,218B for [tags, value] BINARY: 6,073,676 values, 1,295,394B raw, 752,119B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 44,452 entries, 968,440B raw, 44,452B comp}\n","May 3, 2024 8:47:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 35,912,623B for [latitude] DOUBLE: 5,720,100 values, 45,760,800B raw, 35,910,512B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:36 PM INFO: 2024-05-03 20:47:36 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 18000000\n","2024-05-03 20:47:37 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 19000000\n","2024-05-03 20:47:39 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 20000000\n","2024-05-03 20:47:39 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 21000000\n","2024-05-03 20:47:40 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 22000000\n","2024-05-03 20:47:41 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 23000000\n","2024-05-03 20:47:43 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 24000000\n","2024-05-03 20:47:44 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 25000000\n","2024-05-03 20:47:45 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 26000000\n","2024-05-03 20:47:47 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 27000000\n","2024-05-03 20:47:48 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 28000000\n","2024-05-03 20:47:51 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 29000000\n","2024-05-03 20:47:57 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 30000000\n","2024-05-03 20:48:02 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 31000000\n","2024-05-03 20:48:08 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 32000000\n","2024-05-03 20:48:14 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 33000000\n","org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 44,646,560B for [longitude] DOUBLE: 5,720,100 values, 45,760,800B raw, 44,644,449B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,890,784 > 134,217,728: flushing 5,980,100 records to disk.\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,739,943\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,174,785B for [id] INT64: 5,980,100 values, 47,840,800B raw, 24,172,578B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 899,864B for [version] INT32: 5,980,100 values, 1,435,696B raw, 898,967B comp, 23 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 52 entries, 208B raw, 52B comp}\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,747,911B for [timestamp] INT64: 5,980,100 values, 36,558,600B raw, 5,745,716B comp, 46 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY, BIT_PACKED], dic { 119,269 entries, 954,152B raw, 119,269B comp}\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,622B for [changeset] INT64: 5,980,100 values, 552B raw, 644B comp, 46 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,127B for [uid] INT32: 5,980,100 values, 276B raw, 322B comp, 23 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 943B for [user_sid] BINARY: 5,980,100 values, 276B raw, 322B comp, 23 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,011,803B for [tags, key] BINARY: 7,870,933 values, 4,576,658B raw, 2,009,892B comp, 37 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 2,191 entries, 39,639B raw, 2,191B comp}\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,431,283B for [tags, value] BINARY: 7,870,933 values, 36,641,009B raw, 9,427,462B comp, 44 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY], dic { 45,802 entries, 1,023,324B raw, 45,802B comp}\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41,085,665B for [latitude] DOUBLE: 5,980,100 values, 47,840,800B raw, 41,083,458B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:47:43 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,743,212B for [longitude] DOUBLE: 5,980,100 values, 47,840,800B raw, 46,741,005B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,442,991 > 134,217,728: flushing 2,277,488 records to disk.\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,779,549\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,171,968B for [id] INT64: 2,277,488 values, 18,219,904B raw, 9,171,105B comp, 18 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 962,375B for [version] INT32: 2,277,488 values, 1,533,038B raw, 962,024B comp, 9 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 97 entries, 388B raw, 97B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 6,401,304B for [timestamp] INT64: 2,277,488 values, 16,677,273B raw, 6,400,443B comp, 18 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY, BIT_PACKED], dic { 128,005 entries, 1,024,040B raw, 128,005B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,026B for [changeset] INT64: 2,277,488 values, 216B raw, 252B comp, 18 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 441B for [uid] INT32: 2,277,488 values, 108B raw, 126B comp, 9 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 369B for [user_sid] BINARY: 2,277,488 values, 108B raw, 126B comp, 9 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,770,831B for [tags, key] BINARY: 6,093,476 values, 9,274,863B raw, 3,767,376B comp, 67 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 2,110 entries, 36,747B raw, 2,110B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 19,865,712B for [tags, value] BINARY: 6,093,476 values, 231,082,648B raw, 19,849,660B comp, 226 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY], dic { 40,315 entries, 946,508B raw, 40,315B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 8,309,624B for [nodes, index] INT32: 19,407,748 values, 29,358,760B raw, 8,306,621B comp, 77 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 1,801 entries, 7,204B raw, 1,801B comp}\n","May 3, 2024 8:48:02 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 81,221,040B for [nodes, nodeId] INT64: 19,407,748 values, 158,023,974B raw, 81,213,793B comp, 151 pages, encodings: [RLE, PLAIN]\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 114,748,302\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 19,866,400B for [id] INT64: 4,887,681 values, 39,101,448B raw, 19,864,577B comp, 38 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 554,671B for [version] INT32: 4,887,681 values, 853,283B raw, 553,931B comp, 19 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 28 entries, 112B raw, 28B comp}\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,345,046B for [timestamp] INT64: 4,887,681 values, 21,741,704B raw, 3,343,241B comp, 38 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY, BIT_PACKED], dic { 126,777 entries, 1,014,216B raw, 126,777B comp}\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,166B for [changeset] INT64: 4,887,681 values, 456B raw, 532B comp, 38 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 931B for [uid] INT32: 4,887,681 values, 228B raw, 266B comp, 19 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 779B for [user_sid] BINARY: 4,887,681 values, 228B raw, 266B comp, 19 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,348,732B for [tags, key] BINARY: 6,651,030 values, 4,391,603B raw, 2,346,839B comp, 38 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 2,187 entries, 40,336B raw, 2,187B comp}\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,225,192B for [tags, value] BINARY: 6,651,030 values, 32,407,368B raw, 9,222,558B comp, 35 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY], dic { 43,114 entries, 925,361B raw, 43,114B comp}\n","May 3, 2024 8:48:17 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 36,201,000B for [latitude] D2024-05-03 20:48:18 INFO  App$MultiEntitySinkObserver:123 - Total entities processed: 33460220\n","OUBLE: 4,887,681 values, 39,101,448B raw, 36,199,177B comp, 38 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 38,827,354B for [longitude] DOUBLE: 4,887,681 values, 39,101,448B raw, 38,825,531B comp, 38 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 126,326,110\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,633,163B for [id] INT64: 2,352,792 values, 18,822,336B raw, 9,632,300B comp, 18 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 801,888B for [version] INT32: 2,352,792 values, 1,218,843B raw, 801,537B comp, 9 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 76 entries, 304B raw, 76B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,854,596B for [timestamp] INT64: 2,352,792 values, 17,265,958B raw, 5,853,735B comp, 18 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY, BIT_PACKED], dic { 94,012 entries, 752,096B raw, 94,012B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,026B for [changeset] INT64: 2,352,792 values, 216B raw, 252B comp, 18 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 441B for [uid] INT32: 2,352,792 values, 108B raw, 126B comp, 9 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 369B for [user_sid] BINARY: 2,352,792 values, 108B raw, 126B comp, 9 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,842,472B for [tags, key] BINARY: 6,490,745 values, 9,833,430B raw, 4,838,916B comp, 71 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 2,607 entries, 46,345B raw, 2,607B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 17,302,572B for [tags, value] BINARY: 6,490,745 values, 113,609,214B raw, 17,289,343B comp, 169 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY], dic { 42,289 entries, 1,045,832B raw, 42,289B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 6,714,076B for [nodes, index] INT32: 18,488,714 values, 27,768,432B raw, 6,711,229B comp, 73 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 1,621 entries, 6,484B raw, 1,621B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 73,920,303B for [nodes, nodeId] INT64: 18,488,714 values, 150,441,442B raw, 73,913,392B comp, 144 pages, encodings: [RLE, PLAIN]\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 17,296,999\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 424,316B for [id] INT64: 101,858 values, 814,864B raw, 424,269B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 71,846B for [version] INT32: 101,858 values, 102,039B raw, 71,807B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 326 entries, 1,304B raw, 326B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 147,045B for [timestamp] INT64: 101,858 values, 182,373B raw, 146,998B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 38,025 entries, 304,200B raw, 38,025B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 57B for [changeset] INT64: 101,858 values, 12B raw, 14B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 49B for [uid] INT32: 101,858 values, 12B raw, 14B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41B for [user_sid] BINARY: 101,858 values, 12B raw, 14B comp, 1 pages, encodings: [RLE, PLAIN_DICTIONARY, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 251,578B for [tags, key] BINARY: 507,558 values, 759,226B raw, 251,273B comp, 6 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 1,368 entries, 21,273B raw, 1,368B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,289,844B for [tags, value] BINARY: 507,558 values, 6,826,047B raw, 2,288,760B comp, 9 pages, encodings: [RLE, PLAIN, PLAIN_DICTIONARY], dic { 35,780 entries, 819,519B raw, 35,780B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,249,033B for [members, id] INT64: 2,163,901 values, 17,450,838B raw, 9,248,218B comp, 17 pages, encodings: [RLE, PLAIN]\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 357,429B for [members, role] BINARY: 2,163,901 values, 709,751B raw, 356,911B comp, 15 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 305 entries, 3,088B raw, 305B comp}\n","May 3, 2024 8:48:18 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 237,372B for [members, type] BINARY: 2,163,901 values, 295,338B raw, 236,764B comp, 16 pages, encodings: [RLE, PLAIN_DICTIONARY], dic { 3 entries, 27B raw, 3B comp}\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/geodata/osm-parquetizer-1.0.0.jar) to method sun.security.krb5.Config.getInstance()\n","WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","2024-05-03 20:48:19 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:48:19 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:48:19 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n","SLF4J: Defaulting to no-operation (NOP) logger implementation\n","SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n","2024-05-03 20:48:21 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 1000000\n","2024-05-03 20:48:22 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 2000000\n","2024-05-03 20:48:23 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 3000000\n","2024-05-03 20:48:24 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 4000000\n","2024-05-03 20:48:25 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 5000000\n","2024-05-03 20:48:26 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 6000000\n","2024-05-03 20:48:27 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 7000000\n","2024-05-03 20:48:28 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 8000000\n","2024-05-03 20:48:29 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 9000000\n","2024-05-03 20:48:30 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 10000000\n","2024-05-03 20:48:31 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 11000000\n","2024-05-03 20:48:33 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 12000000\n","2024-05-03 20:48:34 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 13000000\n","2024-05-03 20:48:35 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 14000000\n","2024-05-03 20:48:36 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 15000000\n","2024-05-03 20:48:37 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 16000000\n","2024-05-03 20:48:38 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 17000000\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,568,419 > 134,217,728: flushing 5,950,100 records to disk.\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,731,835\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,008,001B for [id] INT64: 5,950,100 values, 47,600,800B raw, 24,005,794B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,233,264B for [version] INT32: 5,950,100 values, 3,615,321B raw, 2,232,367B comp, 23 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 94 entries, 376B raw, 94B comp}\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 10,839,636B for [timestamp] INT64: 5,950,100 values, 44,415,914B raw, 10,837,433B comp, 46 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 129,447 entries, 1,035,576B raw, 129,447B comp}\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,622B for [changeset] INT64: 5,950,100 values, 552B raw, 644B comp, 46 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,127B for [uid] INT32: 5,950,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 943B for [user_sid] BINARY: 5,950,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 532,392B for [tags, key] BINARY: 6,154,690 values, 721,314B raw, 532,127B comp, 5 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,497 entries, 24,553B raw, 1,497B comp}\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,117,151B for [tags, value] BINARY: 6,154,690 values, 2,063,760B raw, 1,116,849B comp, 5 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 42,618 entries, 794,440B raw, 42,618B comp}\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 45,282,215B for [latitude] DOUBLE: 5,950,100 values, 47,600,800B raw, 45,280,008B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:26 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,937,196B for [longitude] DOUBLE: 5,950,100 values, 47,600,800B raw, 46,934,989B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:31 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,278,559 > 134,217,728: flushing 5,200,100 records to disk.\n","May 3, 2024 8:48:31 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 126,853,371\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 20,977,335B for [id] INT64: 5,200,100 values, 41,600,800B raw, 20,975,416B comp, 40 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,057,453B for [version] INT32: 5,200,100 values, 1,642,582B raw, 1,056,673B comp, 20 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 33 entries, 132B raw, 33B comp}\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 6,167,783B for [timestamp] INT64: 5,200,100 values, 33,718,951B raw, 6,165,873B comp, 40 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 123,171 entries, 985,368B raw, 123,171B comp}\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,280B for [changeset] INT64: 5,200,100 values, 480B raw, 560B comp, 40 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 980B for [uid] INT32: 5,200,100 values, 240B raw, 280B comp, 20 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 820B for [user_sid] BINARY: 5,200,100 values, 240B raw, 280B comp, 20 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 519,258B for [tags, key] BINARY: 5,771,565 values, 1,372,865B raw, 519,210B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,296 entries, 22,013B raw, 1,296B comp}\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,913,271B for [tags, value] BINARY: 5,771,565 values, 10,574,208B raw, 2,913,211B comp, 1 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 39,087,495B for [latitude] DOUBLE: 5,200,100 values, 41,600,800B raw, 39,085,576B comp, 40 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 40,956,022B for [longitude] DOUBLE: 5,200,100 values, 41,600,800B raw, 40,954,103B comp, 40 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,262,220 > 134,217,728: flushing 6,130,100 records to disk.\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 132,081,704\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,697,419B for [id] INT64: 6,130,100 values, 49,040,800B raw, 24,695,164B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 703,856B for [version] INT32: 6,130,100 values, 1,119,634B raw, 702,920B comp, 24 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 32 entries, 128B raw, 32B comp}\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,503,829B for [timestamp] INT64: 6,130,100 values, 31,832,051B raw, 4,501,592B comp, 47 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 124,478 entries, 995,824B raw, 124,478B comp}\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,679B for [changeset] INT64: 6,130,100 values, 564B raw, 658B comp, 47 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,176B for [uid] INT32: 6,130,100 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 984B for [user_sid] BINARY: 6,130,100 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 422,463B for [tags, key] BINARY: 6,302,680 values, 597,268B raw, 422,416B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,175 entries, 19,980B raw, 1,175B comp}\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,734,413B for [tags, value] BINARY: 6,302,680 values, 4,514,231B raw, 1,734,366B comp, 1 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 45,044,517B for [latitude] DOUBLE: 6,130,100 values, 49,040,800B raw, 45,042,262B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:38 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 47,537,628B for [longitude] DOUBLE: 6,130,100 v2024-05-03 20:48:39 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 18000000\n","2024-05-03 20:48:40 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 19000000\n","2024-05-03 20:48:41 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 20000000\n","2024-05-03 20:48:42 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 21000000\n","2024-05-03 20:48:43 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 22000000\n","2024-05-03 20:48:44 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 23000000\n","2024-05-03 20:48:45 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 24000000\n","2024-05-03 20:48:46 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 25000000\n","2024-05-03 20:48:47 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 26000000\n","2024-05-03 20:48:47 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 27000000\n","2024-05-03 20:48:49 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 28000000\n","2024-05-03 20:48:50 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 29000000\n","2024-05-03 20:48:51 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 30000000\n","2024-05-03 20:48:52 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 31000000\n","2024-05-03 20:48:53 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 32000000\n","2024-05-03 20:48:54 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 33000000\n","2024-05-03 20:48:55 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 34000000\n","2024-05-03 20:48:56 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 35000000\n","alues, 49,040,800B raw, 47,535,373B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,627,785 > 134,217,728: flushing 6,420,100 records to disk.\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,765,323\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 25,849,069B for [id] INT64: 6,420,100 values, 51,360,800B raw, 25,846,718B comp, 49 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 586,694B for [version] INT32: 6,420,100 values, 944,481B raw, 585,720B comp, 25 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 27 entries, 108B raw, 27B comp}\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,884,861B for [timestamp] INT64: 6,420,100 values, 29,030,332B raw, 3,882,533B comp, 49 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 127,360 entries, 1,018,880B raw, 127,360B comp}\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,793B for [changeset] INT64: 6,420,100 values, 588B raw, 686B comp, 49 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,225B for [uid] INT32: 6,420,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,025B for [user_sid] BINARY: 6,420,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 536,102B for [tags, key] BINARY: 6,763,031 values, 913,146B raw, 535,891B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,285 entries, 21,595B raw, 1,285B comp}\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,472,333B for [tags, value] BINARY: 6,763,031 values, 3,519,876B raw, 1,472,185B comp, 3 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 36,098 entries, 756,938B raw, 36,098B comp}\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 47,638,363B for [latitude] DOUBLE: 6,420,100 values, 51,360,800B raw, 47,636,012B comp, 49 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:44 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 50,107,123B for [longitude] DOUBLE: 6,420,100 values, 51,360,800B raw, 50,104,772B comp, 49 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,408,397 > 134,217,728: flushing 5,364,404 records to disk.\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 115,866,068\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 21,513,259B for [id] INT64: 5,364,404 values, 42,915,232B raw, 21,511,292B comp, 41 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 236,458B for [version] INT32: 5,364,404 values, 382,627B raw, 235,652B comp, 21 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 19 entries, 76B raw, 19B comp}\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 684,161B for [timestamp] INT64: 5,364,404 values, 1,123,280B raw, 682,250B comp, 41 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 39,683 entries, 317,464B raw, 39,683B comp}\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,337B for [changeset] INT64: 5,364,404 values, 492B raw, 574B comp, 41 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,029B for [uid] INT32: 5,364,404 values, 252B raw, 294B comp, 21 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 861B for [user_sid] BINARY: 5,364,404 values, 252B raw, 294B comp, 21 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 236,271B for [tags, key] BINARY: 6,127,874 values, 1,399,454B raw, 236,216B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 831 entries, 13,742B raw, 831B comp}\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 981,575B for [tags, value] BINARY: 6,127,874 values, 2,010,318B raw, 981,504B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 27,672 entries, 562,459B raw, 27,672B comp}\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 38,866,530B for [latitude] DOUBLE: 5,364,404 values, 42,915,232B raw, 38,864,563B comp, 41 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:50 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41,769,849B for [longitude] DOUBLE: 5,364,404 values, 42,915,232B raw, 41,767,882B comp, 41 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,692,607 > 134,217,728: flushing 6,010,100 records to disk.\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 130,682,837\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,173,566B for [id] INT64: 6,010,100 values, 48,080,800B raw, 24,171,359B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 300,962B for [version] INT32: 6,010,100 values, 457,641B raw, 300,077B comp, 23 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 18 entries, 72B raw, 18B comp}\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,110,067B for [timestamp] INT64: 6,010,100 values, 1,546,296B raw, 1,107,917B comp, 46 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 83,503 entries, 668,024B raw, 83,503B comp}\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,622B for [changeset] INT64: 6,010,100 values, 552B raw, 644B comp, 46 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,127B for [uid] INT32: 6,010,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 943B for [user_sid] BINARY: 6,010,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 501,923B for [tags, key] BINARY: 6,300,425 values, 873,588B raw, 501,877B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,519 entries, 25,129B raw, 1,519B comp}\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,972,374B for [tags, value] BINARY: 6,300,425 values, 6,548,296B raw, 1,972,320B comp, 1 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:48:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 44,166,666B for [latitude] DOUBLE: 6,010,100 values, 48,080,800B raw, 44,164,459B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:48:56 PM INFO: org.apache2024-05-03 20:48:57 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 36000000\n","2024-05-03 20:48:58 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 37000000\n","2024-05-03 20:48:59 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 38000000\n","2024-05-03 20:49:00 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 39000000\n","2024-05-03 20:49:01 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 40000000\n","2024-05-03 20:49:02 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 41000000\n","2024-05-03 20:49:08 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 42000000\n","2024-05-03 20:49:14 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 43000000\n","2024-05-03 20:49:19 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 44000000\n","2024-05-03 20:49:25 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 45000000\n","2024-05-03 20:49:31 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 46000000\n",".parquet.hadoop.ColumnChunkPageWriteStore: written 46,878,479B for [longitude] DOUBLE: 6,010,100 values, 48,080,800B raw, 46,876,272B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,286,334 > 134,217,728: flushing 1,800,100 records to disk.\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 133,963,087\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 7,420,310B for [id] INT64: 1,800,100 values, 14,400,800B raw, 7,419,639B comp, 14 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 926,092B for [version] INT32: 1,800,100 values, 1,212,111B raw, 925,819B comp, 7 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 94 entries, 376B raw, 94B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,579,345B for [timestamp] INT64: 1,800,100 values, 13,630,152B raw, 5,578,675B comp, 14 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 75,225 entries, 601,800B raw, 75,225B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 798B for [changeset] INT64: 1,800,100 values, 168B raw, 196B comp, 14 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 343B for [uid] INT32: 1,800,100 values, 84B raw, 98B comp, 7 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 287B for [user_sid] BINARY: 1,800,100 values, 84B raw, 98B comp, 7 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,523,749B for [tags, key] BINARY: 3,889,083 values, 5,345,164B raw, 3,521,686B comp, 42 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 2,358 entries, 40,975B raw, 2,358B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 11,931,427B for [tags, value] BINARY: 3,889,083 values, 38,133,041B raw, 11,928,334B comp, 42 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 43,231 entries, 974,988B raw, 43,231B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,839,868B for [nodes, index] INT32: 21,802,985 values, 32,428,330B raw, 9,836,514B comp, 86 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,893 entries, 7,572B raw, 1,893B comp}\n","May 3, 2024 8:49:14 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 88,871,669B for [nodes, nodeId] INT64: 21,802,985 values, 176,830,453B raw, 88,863,558B comp, 169 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 135,241,279 > 134,217,728: flushing 2,580,100 records to disk.\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,740,809\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 10,479,890B for [id] INT64: 2,580,100 values, 20,640,800B raw, 10,478,931B comp, 20 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 474,268B for [version] INT32: 2,580,100 values, 810,860B raw, 473,878B comp, 10 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 44 entries, 176B raw, 44B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,964,981B for [timestamp] INT64: 2,580,100 values, 16,258,282B raw, 2,964,027B comp, 20 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED, RLE], dic { 129,290 entries, 1,034,320B raw, 129,290B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,140B for [changeset] INT64: 2,580,100 values, 240B raw, 280B comp, 20 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 490B for [uid] INT32: 2,580,100 values, 120B raw, 140B comp, 10 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 410B for [user_sid] BINARY: 2,580,100 values, 120B raw, 140B comp, 10 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,890,904B for [tags, key] BINARY: 4,617,811 values, 6,025,315B raw, 2,888,409B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,950 entries, 33,493B raw, 1,950B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 8,213,168B for [tags, value] BINARY: 4,617,811 values, 29,400,323B raw, 8,209,905B comp, 48 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 44,330 entries, 1,026,607B raw, 44,330B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 10,905,406B for [nodes, index] INT32: 23,737,752 values, 35,630,669B raw, 10,901,740B comp, 94 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,878 entries, 7,512B raw, 1,878B comp}\n","May 3, 2024 8:49:28 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 92,797,069B for [nodes, nodeId] INT64: 23,737,752 values, 192,910,216B raw, 92,788,238B comp, 184 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 126,124,749\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,695,638B for [id] INT64: 6,130,319 values, 49,042,552B raw, 24,693,383B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 227,867B for [version] INT32: 6,130,319 values, 338,437B raw, 226,941B comp, 24 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 14 entries, 56B raw, 14B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,169,342B for [timestamp] INT64: 6,130,319 values, 1,524,808B raw, 1,167,133B comp, 47 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 95,712 entries, 765,696B raw, 95,712B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,679B for [changeset] INT64: 6,130,319 values, 564B raw, 658B comp, 47 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,176B for [uid] INT32: 6,130,319 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 984B for [user_sid] BINARY: 6,130,319 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 757,062B for [tags, key] BINARY: 6,528,899 values, 1,215,191B raw, 756,602B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,497 entries, 26,561B raw, 1,497B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,718,055B for [tags, value] BINARY: 6,528,899 values, 3,979,358B raw, 1,717,308B comp, 8 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 36,511 entries, 842,241B raw, 36,511B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 45,321,090B for 2024-05-03 20:49:32 INFO  App$MultiEntitySinkObserver:123 - Total entities processed: 46000409\n","[latitude] DOUBLE: 6,130,319 values, 49,042,552B raw, 45,318,835B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 47,717,500B for [longitude] DOUBLE: 6,130,319 values, 49,042,552B raw, 47,715,245B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 19,745,211\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,228,844B for [id] INT64: 299,750 values, 2,398,000B raw, 1,228,701B comp, 3 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 44,545B for [version] INT32: 299,750 values, 71,573B raw, 44,469B comp, 2 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 24 entries, 96B raw, 24B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 233,715B for [timestamp] INT64: 299,750 values, 261,862B raw, 233,574B comp, 3 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 31,783 entries, 254,264B raw, 31,783B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 171B for [changeset] INT64: 299,750 values, 36B raw, 42B comp, 3 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 98B for [uid] INT32: 299,750 values, 24B raw, 28B comp, 2 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 82B for [user_sid] BINARY: 299,750 values, 24B raw, 28B comp, 2 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 481,818B for [tags, key] BINARY: 586,970 values, 753,564B raw, 481,487B comp, 7 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,066 entries, 17,558B raw, 1,066B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 659,237B for [tags, value] BINARY: 586,970 values, 981,902B raw, 658,842B comp, 7 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 16,504 entries, 364,160B raw, 16,504B comp}\n","May 3, 2024 8:49:31 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,487,322B for [nodes, index] INT32: 3,254,798 values, 4,795,111B raw, 1,486,815B comp, 13 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,888 entries, 7,552B raw, 1,888B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 12,769,514B for [nodes, nodeId] INT64: 3,254,798 values, 26,415,394B raw, 12,768,267B comp, 26 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 12,824,918\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 482,322B for [id] INT64: 115,235 values, 921,880B raw, 482,275B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 67,699B for [version] INT32: 115,235 values, 106,604B raw, 67,660B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 292 entries, 1,168B raw, 292B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 177,195B for [timestamp] INT64: 115,235 values, 211,084B raw, 177,148B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 45,972 entries, 367,776B raw, 45,972B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 57B for [changeset] INT64: 115,235 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 49B for [uid] INT32: 115,235 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41B for [user_sid] BINARY: 115,235 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, BIT_PACKED, RLE], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 302,929B for [tags, key] BINARY: 419,819 values, 626,573B raw, 302,705B comp, 5 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,601 entries, 24,853B raw, 1,601B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,071,598B for [tags, value] BINARY: 419,819 values, 2,972,916B raw, 1,071,047B comp, 7 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 43,656 entries, 1,015,433B raw, 43,656B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,159,646B for [members, id] INT64: 1,256,695 values, 10,140,704B raw, 5,159,167B comp, 10 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 225,254B for [members, role] BINARY: 1,256,695 values, 412,262B raw, 224,973B comp, 8 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 175 entries, 2,311B raw, 175B comp}\n","May 3, 2024 8:49:32 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 121,578B for [members, type] BINARY: 1,256,695 values, 144,123B raw, 121,237B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 3 entries, 27B raw, 3B comp}\n","WARNING: An illegal reflective access operation has occurred\n","WARNING: Illegal reflective access by org.apache.hadoop.security.authentication.util.KerberosUtil (file:/geodata/osm-parquetizer-1.0.0.jar) to method sun.security.krb5.Config.getInstance()\n","WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.security.authentication.util.KerberosUtil\n","WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","WARNING: All illegal access operations will be denied in a future release\n","2024-05-03 20:49:32 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:49:32 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","2024-05-03 20:49:33 INFO  CodecPool:153 - Got brand-new compressor [.snappy]\n","SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n","SLF4J: Defaulting to no-operation (NOP) logger implementation\n","SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n","2024-05-03 20:49:35 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 1000000\n","2024-05-03 20:49:36 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 2000000\n","2024-05-03 20:49:37 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 3000000\n","2024-05-03 20:49:38 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 4000000\n","2024-05-03 20:49:39 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 5000000\n","2024-05-03 20:49:39 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 6000000\n","2024-05-03 20:49:41 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 7000000\n","2024-05-03 20:49:42 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 8000000\n","2024-05-03 20:49:43 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 9000000\n","2024-05-03 20:49:44 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 10000000\n","2024-05-03 20:49:46 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 11000000\n","2024-05-03 20:49:47 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 12000000\n","2024-05-03 20:49:48 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 13000000\n","2024-05-03 20:49:49 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 14000000\n","2024-05-03 20:49:50 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 15000000\n","2024-05-03 20:49:51 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 16000000\n","May 3, 2024 8:49:39 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,597,854 > 134,217,728: flushing 6,010,100 records to disk.\n","May 3, 2024 8:49:39 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,456,378\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,172,047B for [id] INT64: 6,010,100 values, 48,080,800B raw, 24,169,840B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 975,806B for [version] INT32: 6,010,100 values, 1,810,248B raw, 974,910B comp, 23 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 78 entries, 312B raw, 78B comp}\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,348,833B for [timestamp] INT64: 6,010,100 values, 44,808,263B raw, 9,346,630B comp, 46 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 128,399 entries, 1,027,192B raw, 128,399B comp}\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,622B for [changeset] INT64: 6,010,100 values, 552B raw, 644B comp, 46 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,127B for [uid] INT32: 6,010,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 943B for [user_sid] BINARY: 6,010,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 374,452B for [tags, key] BINARY: 6,180,759 values, 585,144B raw, 374,250B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 989 entries, 15,809B raw, 989B comp}\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 549,420B for [tags, value] BINARY: 6,180,759 values, 774,206B raw, 549,055B comp, 5 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 25,622 entries, 599,360B raw, 25,622B comp}\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,827,607B for [latitude] DOUBLE: 6,010,100 values, 48,080,800B raw, 46,825,399B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,746,598B for [longitude] DOUBLE: 6,010,100 values, 48,080,800B raw, 46,744,387B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:44 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,338,817 > 134,217,728: flushing 4,380,100 records to disk.\n","May 3, 2024 8:49:44 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 108,404,020\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 17,585,087B for [id] INT64: 4,380,100 values, 35,040,800B raw, 17,583,456B comp, 34 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 622,621B for [version] INT32: 4,380,100 values, 1,154,396B raw, 621,958B comp, 17 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 21 entries, 84B raw, 21B comp}\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,882,316B for [timestamp] INT64: 4,380,100 values, 30,802,890B raw, 5,880,690B comp, 34 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 128,949 entries, 1,031,592B raw, 128,949B comp}\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,938B for [changeset] INT64: 4,380,100 values, 408B raw, 476B comp, 34 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 833B for [uid] INT32: 4,380,100 values, 204B raw, 238B comp, 17 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 697B for [user_sid] BINARY: 4,380,100 values, 204B raw, 238B comp, 17 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 748,550B for [tags, key] BINARY: 5,273,804 values, 2,125,130B raw, 748,502B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 402 entries, 6,148B raw, 402B comp}\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,248,510B for [tags, value] BINARY: 5,273,804 values, 3,361,464B raw, 2,248,455B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 45,961 entries, 638,911B raw, 45,961B comp}\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 34,281,057B for [latitude] DOUBLE: 4,380,100 values, 35,040,800B raw, 34,279,426B comp, 34 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:45 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 34,318,701B for [longitude] DOUBLE: 4,380,100 values, 35,040,800B raw, 34,317,070B comp, 34 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,422,850 > 134,217,728: flushing 6,000,100 records to disk.\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,871,497\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,097,191B for [id] INT64: 6,000,100 values, 48,000,800B raw, 24,094,984B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 778,496B for [version] INT32: 6,000,100 values, 1,370,539B raw, 777,600B comp, 23 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 24 entries, 96B raw, 24B comp}\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 7,519,994B for [timestamp] INT64: 6,000,100 values, 43,028,055B raw, 7,517,793B comp, 46 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 127,109 entries, 1,016,872B raw, 127,109B comp}\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,622B for [changeset] INT64: 6,000,100 values, 552B raw, 644B comp, 46 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,127B for [uid] INT32: 6,000,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 943B for [user_sid] BINARY: 6,000,100 values, 276B raw, 322B comp, 23 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,017,075B for [tags, key] BINARY: 7,247,605 values, 2,747,074B raw, 1,015,985B comp, 22 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 655 entries, 10,856B raw, 655B comp}\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,118,870B for [tags, value] BINARY: 7,247,605 values, 4,412,797B raw, 3,117,627B comp, 24 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 63,408 entries, 1,021,052B raw, 63,408B comp}\n","May 3, 2024 8:49:51 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 45,731,450B for [latitude] DOUBLE: 6,000,100 values, 48,000,800B raw, 45,729,243B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:51 PM INFO: org.apach2024-05-03 20:49:52 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 17000000\n","2024-05-03 20:49:53 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 18000000\n","2024-05-03 20:49:54 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 19000000\n","2024-05-03 20:49:55 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 20000000\n","2024-05-03 20:49:56 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 21000000\n","2024-05-03 20:49:57 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 22000000\n","2024-05-03 20:49:59 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 23000000\n","2024-05-03 20:49:59 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 24000000\n","2024-05-03 20:50:00 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 25000000\n","2024-05-03 20:50:01 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 26000000\n","2024-05-03 20:50:02 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 27000000\n","2024-05-03 20:50:03 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 28000000\n","2024-05-03 20:50:04 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 29000000\n","2024-05-03 20:50:05 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 30000000\n","2024-05-03 20:50:06 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 31000000\n","2024-05-03 20:50:07 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 32000000\n","2024-05-03 20:50:08 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 33000000\n","2024-05-03 20:50:09 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 34000000\n","e.parquet.hadoop.ColumnChunkPageWriteStore: written 46,430,932B for [longitude] DOUBLE: 6,000,100 values, 48,000,800B raw, 46,428,725B comp, 46 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,378,138 > 134,217,728: flushing 4,700,100 records to disk.\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 109,906,983\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 18,925,240B for [id] INT64: 4,700,100 values, 37,600,800B raw, 18,923,513B comp, 36 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 468,254B for [version] INT32: 4,700,100 values, 760,876B raw, 467,552B comp, 18 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 24 entries, 96B raw, 24B comp}\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,172,659B for [timestamp] INT64: 4,700,100 values, 29,225,176B raw, 5,170,941B comp, 36 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 119,301 entries, 954,408B raw, 119,301B comp}\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,052B for [changeset] INT64: 4,700,100 values, 432B raw, 504B comp, 36 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 882B for [uid] INT32: 4,700,100 values, 216B raw, 252B comp, 18 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 738B for [user_sid] BINARY: 4,700,100 values, 216B raw, 252B comp, 18 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 337,663B for [tags, key] BINARY: 5,545,393 values, 1,733,149B raw, 337,619B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 750 entries, 12,099B raw, 750B comp}\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,474,018B for [tags, value] BINARY: 5,545,393 values, 2,618,128B raw, 1,473,856B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 51,176 entries, 815,247B raw, 51,176B comp}\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 34,139,171B for [latitude] DOUBLE: 4,700,100 values, 37,600,800B raw, 34,137,444B comp, 36 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:49:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 35,402,156B for [longitude] DOUBLE: 4,700,100 values, 37,600,800B raw, 35,400,429B comp, 36 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,654,841 > 134,217,728: flushing 6,540,100 records to disk.\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,991,454\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,256,106B for [id] INT64: 6,540,100 values, 52,320,800B raw, 26,253,707B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 302,285B for [version] INT32: 6,540,100 values, 516,478B raw, 301,324B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 21 entries, 84B raw, 21B comp}\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,561,641B for [timestamp] INT64: 6,540,100 values, 38,918,502B raw, 4,559,256B comp, 50 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 126,542 entries, 1,012,336B raw, 126,542B comp}\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,850B for [changeset] INT64: 6,540,100 values, 600B raw, 700B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,225B for [uid] INT32: 6,540,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,025B for [user_sid] BINARY: 6,540,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 275,769B for [tags, key] BINARY: 7,107,853 values, 1,132,554B raw, 275,290B comp, 10 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 605 entries, 9,413B raw, 605B comp}\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,083,334B for [tags, value] BINARY: 7,107,853 values, 1,761,802B raw, 1,082,682B comp, 11 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 46,336 entries, 663,441B raw, 46,336B comp}\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,325,872B for [latitude] DOUBLE: 6,540,100 values, 52,320,800B raw, 46,323,473B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:03 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 49,452,214B for [longitude] DOUBLE: 6,540,100 values, 52,320,800B raw, 49,449,815B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,520,392 > 134,217,728: flushing 6,550,100 records to disk.\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 132,255,101\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,273,686B for [id] INT64: 6,550,100 values, 52,400,800B raw, 26,271,287B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 102,597B for [version] INT32: 6,550,100 values, 165,700B raw, 101,662B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 16 entries, 64B raw, 16B comp}\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,714,280B for [timestamp] INT64: 6,550,100 values, 34,398,681B raw, 3,711,899B comp, 50 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 130,489 entries, 1,043,912B raw, 130,489B comp}\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,850B for [changeset] INT64: 6,550,100 values, 600B raw, 700B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,225B for [uid] INT32: 6,550,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,025B for [user_sid] BINARY: 6,550,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 97,690B for [tags, key] BINARY: 6,633,609 values, 221,868B raw, 97,642B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 428 entries, 6,692B raw, 428B comp}\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 191,347B for [tags, value] BINARY: 6,633,609 values, 305,470B raw, 191,287B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 9,325 entries, 151,476B raw, 9,325B comp}\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 42024-05-03 20:50:10 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 35000000\n","2024-05-03 20:50:11 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 36000000\n","2024-05-03 20:50:12 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 37000000\n","2024-05-03 20:50:12 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 38000000\n","2024-05-03 20:50:13 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 39000000\n","2024-05-03 20:50:14 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 40000000\n","2024-05-03 20:50:15 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 41000000\n","2024-05-03 20:50:16 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 42000000\n","2024-05-03 20:50:17 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 43000000\n","2024-05-03 20:50:18 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 44000000\n","2024-05-03 20:50:19 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 45000000\n","2024-05-03 20:50:20 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 46000000\n","2024-05-03 20:50:21 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 47000000\n","2024-05-03 20:50:22 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 48000000\n","2024-05-03 20:50:23 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 49000000\n","2024-05-03 20:50:24 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 50000000\n","2024-05-03 20:50:24 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 51000000\n","2024-05-03 20:50:25 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 52000000\n","2024-05-03 20:50:26 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 53000000\n","2024-05-03 20:50:27 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 54000000\n","5,640,937B for [latitude] DOUBLE: 6,550,100 values, 52,400,800B raw, 45,638,538B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 49,457,294B for [longitude] DOUBLE: 6,550,100 values, 52,400,800B raw, 49,454,895B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,329,770 > 134,217,728: flushing 6,670,100 records to disk.\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 133,563,936\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,753,124B for [id] INT64: 6,670,100 values, 53,360,800B raw, 26,750,677B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 92,980B for [version] INT32: 6,670,100 values, 140,243B raw, 92,012B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 16 entries, 64B raw, 16B comp}\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,996,900B for [timestamp] INT64: 6,670,100 values, 33,373,706B raw, 3,994,473B comp, 51 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 127,334 entries, 1,018,672B raw, 127,334B comp}\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,907B for [changeset] INT64: 6,670,100 values, 612B raw, 714B comp, 51 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,274B for [uid] INT32: 6,670,100 values, 312B raw, 364B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,066B for [user_sid] BINARY: 6,670,100 values, 312B raw, 364B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 127,834B for [tags, key] BINARY: 6,719,823 values, 198,007B raw, 127,786B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 431 entries, 6,786B raw, 431B comp}\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 163,680B for [tags, value] BINARY: 6,719,823 values, 249,790B raw, 163,635B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 7,674 entries, 146,438B raw, 7,674B comp}\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,650,138B for [latitude] DOUBLE: 6,670,100 values, 53,360,800B raw, 46,647,691B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:15 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 50,780,627B for [longitude] DOUBLE: 6,670,100 values, 53,360,800B raw, 50,778,180B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,551,807 > 134,217,728: flushing 6,540,100 records to disk.\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 133,378,068\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,232,445B for [id] INT64: 6,540,100 values, 52,320,800B raw, 26,230,046B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 83,122B for [version] INT32: 6,540,100 values, 133,431B raw, 82,191B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 16 entries, 64B raw, 16B comp}\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,271,775B for [timestamp] INT64: 6,540,100 values, 33,509,431B raw, 4,269,395B comp, 50 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 126,744 entries, 1,013,952B raw, 126,744B comp}\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,850B for [changeset] INT64: 6,540,100 values, 600B raw, 700B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,225B for [uid] INT32: 6,540,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,025B for [user_sid] BINARY: 6,540,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 109,753B for [tags, key] BINARY: 6,597,374 values, 210,782B raw, 109,687B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 365 entries, 5,599B raw, 365B comp}\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 171,773B for [tags, value] BINARY: 6,597,374 values, 266,742B raw, 171,726B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 6,013 entries, 95,635B raw, 6,013B comp}\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 45,630,142B for [latitude] DOUBLE: 6,540,100 values, 52,320,800B raw, 45,627,743B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:21 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 50,290,839B for [longitude] DOUBLE: 6,540,100 values, 52,320,800B raw, 50,288,440B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,613,616 > 134,217,728: flushing 6,670,100 records to disk.\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 133,964,701\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,738,872B for [id] INT64: 6,670,100 values, 53,360,800B raw, 26,736,425B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 60,276B for [version] INT32: 6,670,100 values, 92,520B raw, 59,314B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 17 entries, 68B raw, 17B comp}\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,160,476B for [timestamp] INT64: 6,670,100 values, 37,840,800B raw, 4,158,045B comp, 51 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 130,617 entries, 1,044,936B raw, 130,617B comp}\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,907B for [changeset] INT64: 6,670,100 values, 612B raw, 714B comp, 51 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,274B for [uid] INT32: 6,670,100 values, 312B raw, 364B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,066B for [user_sid] BINARY: 6,670,100 values, 312B raw, 364B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 89,137B for [tags, key] BINARY: 6,706,161 values, 160,187B raw, 89,079B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 304 entries, 4,598B raw, 304B comp}\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 127,879B for [tags, value] BINARY: 6,706,161 values, 199,785B raw, 127,827B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE]2024-05-03 20:50:28 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 55000000\n","2024-05-03 20:50:29 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 56000000\n","2024-05-03 20:50:30 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 57000000\n","2024-05-03 20:50:31 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 58000000\n","2024-05-03 20:50:32 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 59000000\n","2024-05-03 20:50:33 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 60000000\n","2024-05-03 20:50:34 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 61000000\n","2024-05-03 20:50:35 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 62000000\n","2024-05-03 20:50:36 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 63000000\n","2024-05-03 20:50:37 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 64000000\n","2024-05-03 20:50:37 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 65000000\n","2024-05-03 20:50:38 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 66000000\n","2024-05-03 20:50:39 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 67000000\n","2024-05-03 20:50:41 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 68000000\n","2024-05-03 20:50:42 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 69000000\n","2024-05-03 20:50:42 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 70000000\n","2024-05-03 20:50:43 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 71000000\n","2024-05-03 20:50:44 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 72000000\n","2024-05-03 20:50:45 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 73000000\n",", dic { 4,759 entries, 75,594B raw, 4,759B comp}\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,420,836B for [latitude] DOUBLE: 6,670,100 values, 53,360,800B raw, 46,418,389B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:27 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 51,580,551B for [longitude] DOUBLE: 6,670,100 values, 53,360,800B raw, 51,578,104B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:33 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,345,862 > 134,217,728: flushing 6,680,100 records to disk.\n","May 3, 2024 8:50:33 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 133,521,191\n","May 3, 2024 8:50:33 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,781,299B for [id] INT64: 6,680,100 values, 53,440,800B raw, 26,778,852B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:33 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 65,906B for [version] INT32: 6,680,100 values, 97,194B raw, 64,943B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 15 entries, 60B raw, 15B comp}\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,295,942B for [timestamp] INT64: 6,680,100 values, 30,506,687B raw, 3,293,518B comp, 51 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 130,764 entries, 1,046,112B raw, 130,764B comp}\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,907B for [changeset] INT64: 6,680,100 values, 612B raw, 714B comp, 51 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,274B for [uid] INT32: 6,680,100 values, 312B raw, 364B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,066B for [user_sid] BINARY: 6,680,100 values, 312B raw, 364B comp, 26 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 73,963B for [tags, key] BINARY: 6,716,561 values, 114,106B raw, 73,917B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 465 entries, 7,217B raw, 465B comp}\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 112,701B for [tags, value] BINARY: 6,716,561 values, 147,401B raw, 112,607B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 8,119 entries, 160,530B raw, 8,119B comp}\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 47,175,761B for [latitude] DOUBLE: 6,680,100 values, 53,440,800B raw, 47,173,314B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:34 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 51,320,299B for [longitude] DOUBLE: 6,680,100 values, 53,440,800B raw, 51,317,852B comp, 51 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:39 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,580,913 > 134,217,728: flushing 6,530,100 records to disk.\n","May 3, 2024 8:50:39 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 132,331,093\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,192,623B for [id] INT64: 6,530,100 values, 52,240,800B raw, 26,190,224B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 160,451B for [version] INT32: 6,530,100 values, 238,877B raw, 159,514B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 17 entries, 68B raw, 17B comp}\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,109,836B for [timestamp] INT64: 6,530,100 values, 25,103,139B raw, 3,107,464B comp, 50 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 128,923 entries, 1,031,384B raw, 128,923B comp}\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,850B for [changeset] INT64: 6,530,100 values, 600B raw, 700B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,225B for [uid] INT32: 6,530,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,025B for [user_sid] BINARY: 6,530,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 180,360B for [tags, key] BINARY: 6,620,934 values, 306,968B raw, 180,313B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 687 entries, 12,252B raw, 687B comp}\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 267,170B for [tags, value] BINARY: 6,620,934 values, 392,122B raw, 267,101B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 15,293 entries, 310,696B raw, 15,293B comp}\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 45,965,753B for [latitude] DOUBLE: 6,530,100 values, 52,240,800B raw, 45,963,354B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:40 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 50,001,785B for [longitude] DOUBLE: 6,530,100 values, 52,240,800B raw, 49,999,386B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,256,835 > 134,217,728: flushing 6,540,100 records to disk.\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,105,481\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,245,854B for [id] INT64: 6,540,100 values, 52,320,800B raw, 26,243,455B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 165,410B for [version] INT32: 6,540,100 values, 246,179B raw, 164,467B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 15 entries, 60B raw, 15B comp}\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,448,306B for [timestamp] INT64: 6,540,100 values, 19,664,618B raw, 2,445,939B comp, 50 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 130,253 entries, 1,042,024B raw, 130,253B comp}\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,850B for [changeset] INT64: 6,540,100 values, 600B raw, 700B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,225B for [uid] INT32: 6,540,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,025B for [user_sid] BINARY: 6,540,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 203,542B for [tags, key] BINARY: 6,881,229 values, 696,673B raw, 203,403B comp, 3 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 680 entries, 10,843B raw, 680B comp}\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunk2024-05-03 20:50:46 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 74000000\n","2024-05-03 20:50:47 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 75000000\n","2024-05-03 20:50:48 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 76000000\n","2024-05-03 20:50:50 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 77000000\n","2024-05-03 20:50:52 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 78000000\n","2024-05-03 20:50:53 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 79000000\n","2024-05-03 20:50:54 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 80000000\n","2024-05-03 20:50:54 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 81000000\n","2024-05-03 20:50:55 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 82000000\n","2024-05-03 20:50:56 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 83000000\n","2024-05-03 20:50:57 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 84000000\n","2024-05-03 20:50:58 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 85000000\n","2024-05-03 20:50:59 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 86000000\n","2024-05-03 20:51:00 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 87000000\n","2024-05-03 20:51:01 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 88000000\n","2024-05-03 20:51:02 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 89000000\n","2024-05-03 20:51:03 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 90000000\n","2024-05-03 20:51:04 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 91000000\n","PageWriteStore: written 859,578B for [tags, value] BINARY: 6,881,229 values, 1,077,536B raw, 859,320B comp, 5 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 50,984 entries, 900,461B raw, 50,984B comp}\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,674,755B for [latitude] DOUBLE: 6,540,100 values, 52,320,800B raw, 46,672,356B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:46 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 50,150,555B for [longitude] DOUBLE: 6,540,100 values, 52,320,800B raw, 50,148,156B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:51 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,676,199 > 134,217,728: flushing 4,058,022 records to disk.\n","May 3, 2024 8:50:51 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 116,111,701\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 16,306,946B for [id] INT64: 4,058,022 values, 32,464,176B raw, 16,305,459B comp, 31 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 412,364B for [version] INT32: 4,058,022 values, 678,611B raw, 411,748B comp, 16 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 19 entries, 76B raw, 19B comp}\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,047,387B for [timestamp] INT64: 4,058,022 values, 14,183,220B raw, 3,045,920B comp, 31 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 129,106 entries, 1,032,848B raw, 129,106B comp}\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,767B for [changeset] INT64: 4,058,022 values, 372B raw, 434B comp, 31 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 784B for [uid] INT32: 4,058,022 values, 192B raw, 224B comp, 16 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 656B for [user_sid] BINARY: 4,058,022 values, 192B raw, 224B comp, 16 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 398,813B for [tags, key] BINARY: 5,467,133 values, 2,349,392B raw, 398,746B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 659 entries, 10,578B raw, 659B comp}\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,517,063B for [tags, value] BINARY: 5,467,133 values, 25,286,384B raw, 3,517,009B comp, 1 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 27,301,846B for [latitude] DOUBLE: 4,058,022 values, 30,924,614B raw, 27,300,361B comp, 31 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED], dic { 126,108 entries, 1,008,864B raw, 126,108B comp}\n","May 3, 2024 8:50:52 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 29,174,905B for [longitude] DOUBLE: 4,058,022 values, 32,464,176B raw, 29,173,418B comp, 31 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,381,013 > 134,217,728: flushing 6,270,100 records to disk.\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 128,529,236\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 25,137,950B for [id] INT64: 6,270,100 values, 50,160,800B raw, 25,135,647B comp, 48 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 87,369B for [version] INT32: 6,270,100 values, 127,869B raw, 86,474B comp, 24 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 13 entries, 52B raw, 13B comp}\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,612,959B for [timestamp] INT64: 6,270,100 values, 11,217,219B raw, 1,610,694B comp, 48 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 127,996 entries, 1,023,968B raw, 127,996B comp}\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,736B for [changeset] INT64: 6,270,100 values, 576B raw, 672B comp, 48 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,176B for [uid] INT32: 6,270,100 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 984B for [user_sid] BINARY: 6,270,100 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 156,898B for [tags, key] BINARY: 6,477,430 values, 468,736B raw, 156,852B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 550 entries, 9,199B raw, 550B comp}\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 534,290B for [tags, value] BINARY: 6,477,430 values, 667,254B raw, 533,988B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 30,632 entries, 512,528B raw, 30,632B comp}\n","May 3, 2024 8:50:57 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,829,076B for [latitude] DOUBLE: 6,270,100 values, 49,374,630B raw, 46,826,774B comp, 48 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED], dic { 63,877 entries, 511,016B raw, 63,877B comp}\n","May 3, 2024 8:50:58 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,837,801B for [longitude] DOUBLE: 6,270,100 values, 49,374,630B raw, 46,835,499B comp, 48 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED], dic { 64,222 entries, 513,776B raw, 64,222B comp}\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,429,592 > 134,217,728: flushing 7,040,100 records to disk.\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 133,345,957\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 28,210,014B for [id] INT64: 7,040,100 values, 56,320,800B raw, 28,207,423B comp, 54 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 231,548B for [version] INT32: 7,040,100 values, 427,711B raw, 230,520B comp, 27 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 12 entries, 48B raw, 12B comp}\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,022,603B for [timestamp] INT64: 7,040,100 values, 10,999,729B raw, 2,020,057B comp, 54 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 129,298 entries, 1,034,384B raw, 129,298B comp}\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,078B for [changeset] INT64: 7,040,100 values, 648B raw, 756B comp, 54 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,323B for [uid] INT32: 7,040,100 values, 324B raw, 378B comp, 27 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,107B for [user_sid] BINARY: 7,040,100 values, 324B raw, 378B comp, 27 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 82024-05-03 20:51:05 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 92000000\n","2024-05-03 20:51:06 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 93000000\n","2024-05-03 20:51:07 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 94000000\n","2024-05-03 20:51:08 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 95000000\n","2024-05-03 20:51:09 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 96000000\n","2024-05-03 20:51:10 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 97000000\n","2024-05-03 20:51:11 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 98000000\n","2024-05-03 20:51:12 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 99000000\n","2024-05-03 20:51:13 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 100000000\n","2024-05-03 20:51:13 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 101000000\n","2024-05-03 20:51:14 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 102000000\n","2024-05-03 20:51:15 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 103000000\n","2024-05-03 20:51:17 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 104000000\n","2024-05-03 20:51:17 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 105000000\n","2024-05-03 20:51:18 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 106000000\n","2024-05-03 20:51:19 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 107000000\n","2024-05-03 20:51:20 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 108000000\n","2024-05-03 20:51:21 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 109000000\n",":51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 75,763B for [tags, key] BINARY: 7,097,633 values, 140,748B raw, 75,689B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 480 entries, 7,384B raw, 480B comp}\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 153,809B for [tags, value] BINARY: 7,097,633 values, 200,462B raw, 153,761B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 13,046 entries, 228,982B raw, 13,046B comp}\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 48,428,276B for [latitude] DOUBLE: 7,040,100 values, 56,320,800B raw, 48,425,685B comp, 54 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:04 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 48,274,166B for [longitude] DOUBLE: 7,040,100 values, 56,320,800B raw, 48,271,575B comp, 54 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,753,649 > 134,217,728: flushing 6,150,100 records to disk.\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 128,611,576\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 24,690,566B for [id] INT64: 6,150,100 values, 49,200,800B raw, 24,688,311B comp, 47 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 238,398B for [version] INT32: 6,150,100 values, 349,510B raw, 237,479B comp, 24 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 14 entries, 56B raw, 14B comp}\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,292,003B for [timestamp] INT64: 6,150,100 values, 1,620,715B raw, 1,289,814B comp, 47 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 112,129 entries, 897,032B raw, 112,129B comp}\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,679B for [changeset] INT64: 6,150,100 values, 564B raw, 658B comp, 47 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,176B for [uid] INT32: 6,150,100 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 984B for [user_sid] BINARY: 6,150,100 values, 288B raw, 336B comp, 24 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 454,955B for [tags, key] BINARY: 6,775,357 values, 1,227,093B raw, 454,899B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 881 entries, 15,106B raw, 881B comp}\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,527,679B for [tags, value] BINARY: 6,775,357 values, 10,151,421B raw, 2,527,433B comp, 1 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41,763,549B for [latitude] DOUBLE: 6,150,100 values, 47,661,208B raw, 41,761,296B comp, 47 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED], dic { 122,557 entries, 980,456B raw, 122,557B comp}\n","May 3, 2024 8:51:10 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 42,039,345B for [longitude] DOUBLE: 6,150,100 values, 48,431,015B raw, 42,037,091B comp, 47 pages, encodings: [PLAIN_DICTIONARY, PLAIN, BIT_PACKED], dic { 86,773 entries, 694,184B raw, 86,773B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,379,469 > 134,217,728: flushing 6,520,100 records to disk.\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 129,851,109\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 26,181,532B for [id] INT64: 6,520,100 values, 52,160,800B raw, 26,179,133B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 238,499B for [version] INT32: 6,520,100 values, 337,295B raw, 237,546B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 15 entries, 60B raw, 15B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 806,952B for [timestamp] INT64: 6,520,100 values, 1,225,314B raw, 804,631B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 64,605 entries, 516,840B raw, 64,605B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,850B for [changeset] INT64: 6,520,100 values, 600B raw, 700B comp, 50 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,225B for [uid] INT32: 6,520,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,025B for [user_sid] BINARY: 6,520,100 values, 300B raw, 350B comp, 25 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 325,534B for [tags, key] BINARY: 6,679,371 values, 525,266B raw, 325,484B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 835 entries, 13,813B raw, 835B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 496,736B for [tags, value] BINARY: 6,679,371 values, 725,719B raw, 496,675B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 23,355 entries, 507,372B raw, 23,355B comp}\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,981,684B for [latitude] DOUBLE: 6,520,100 values, 52,160,800B raw, 46,979,285B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:16 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 46,731,492B for [longitude] DOUBLE: 6,520,100 values, 52,160,800B raw, 46,729,093B comp, 50 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,395,258 > 134,217,728: flushing 5,760,100 records to disk.\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 123,138,335\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 23,198,856B for [id] INT64: 5,760,100 values, 46,080,800B raw, 23,196,745B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 203,599B for [version] INT32: 5,760,100 values, 309,273B raw, 202,753B comp, 22 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 16 entries, 64B raw, 16B comp}\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,037,123B for [timestamp] INT64: 5,760,100 values, 1,375,846B raw, 1,035,057B comp, 44 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 94,185 entries, 753,480B raw, 94,185B comp}\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,508B for [changeset] INT64: 5,760,100 values, 528B raw, 616B comp, 44 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,078B for [uid] INT32: 5,760,100 values, 264B raw, 308B comp, 22 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.Colum2024-05-03 20:51:22 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 110000000\n","2024-05-03 20:51:23 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 111000000\n","2024-05-03 20:51:24 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 112000000\n","2024-05-03 20:51:32 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 113000000\n","2024-05-03 20:51:39 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 114000000\n","2024-05-03 20:51:53 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 115000000\n","nChunkPageWriteStore: written 902B for [user_sid] BINARY: 5,760,100 values, 264B raw, 308B comp, 22 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 786,296B for [tags, key] BINARY: 6,193,716 values, 1,377,898B raw, 786,249B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,166 entries, 19,874B raw, 1,166B comp}\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,066,732B for [tags, value] BINARY: 6,193,716 values, 1,889,905B raw, 1,066,685B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 55,241 entries, 1,025,454B raw, 55,241B comp}\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 42,107,837B for [latitude] DOUBLE: 5,760,100 values, 46,080,800B raw, 42,105,726B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41,867,386B for [longitude] DOUBLE: 5,760,100 values, 46,080,800B raw, 41,865,275B comp, 44 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,999,211 > 134,217,728: flushing 1,390,100 records to disk.\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,561,927\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,611,743B for [id] INT64: 1,390,100 values, 11,120,800B raw, 5,611,216B comp, 11 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 747,775B for [version] INT32: 1,390,100 values, 1,052,018B raw, 747,541B comp, 6 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 93 entries, 372B raw, 93B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,223,986B for [timestamp] INT64: 1,390,100 values, 9,562,703B raw, 4,223,461B comp, 11 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 85,688 entries, 685,504B raw, 85,688B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 627B for [changeset] INT64: 1,390,100 values, 132B raw, 154B comp, 11 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 294B for [uid] INT32: 1,390,100 values, 72B raw, 84B comp, 6 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 246B for [user_sid] BINARY: 1,390,100 values, 72B raw, 84B comp, 6 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,985,626B for [tags, key] BINARY: 4,991,744 values, 7,362,254B raw, 2,982,762B comp, 59 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,606 entries, 27,303B raw, 1,606B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 15,225,102B for [tags, value] BINARY: 4,991,744 values, 66,919,447B raw, 15,220,192B comp, 69 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 53,025 entries, 977,054B raw, 53,025B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,739,187B for [nodes, index] INT32: 21,443,818 values, 31,661,010B raw, 9,735,911B comp, 84 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 2,000 entries, 8,000B raw, 2,000B comp}\n","May 3, 2024 8:51:36 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 91,809,912B for [nodes, nodeId] INT64: 21,443,818 values, 173,684,299B raw, 91,801,945B comp, 166 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,631,760 > 134,217,728: flushing 1,006,891 records to disk.\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 134,203,361\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,086,893B for [id] INT64: 1,006,891 values, 8,055,128B raw, 4,086,510B comp, 8 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 334,457B for [version] INT32: 1,006,891 values, 530,055B raw, 334,301B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 50 entries, 200B raw, 50B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,225,873B for [timestamp] INT64: 1,006,891 values, 5,607,987B raw, 2,225,493B comp, 8 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 110,323 entries, 882,584B raw, 110,323B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 456B for [changeset] INT64: 1,006,891 values, 96B raw, 112B comp, 8 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 196B for [uid] INT32: 1,006,891 values, 48B raw, 56B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 164B for [user_sid] BINARY: 1,006,891 values, 48B raw, 56B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,340,624B for [tags, key] BINARY: 2,385,063 values, 3,336,444B raw, 1,339,346B comp, 27 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,234 entries, 20,423B raw, 1,234B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,995,434B for [tags, value] BINARY: 2,385,063 values, 13,777,689B raw, 2,992,982B comp, 30 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 49,935 entries, 1,040,018B raw, 49,935B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 10,073,275B for [nodes, index] INT32: 26,090,638 values, 38,010,396B raw, 10,069,297B comp, 102 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 2,000 entries, 8,000B raw, 2,000B comp}\n","May 3, 2024 8:51:47 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 108,270,992B for [nodes, nodeId] INT64: 26,090,638 values, 210,809,811B raw, 108,261,298B comp, 202 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,953,631 > 134,217,728: flushing 830,563 records to disk.\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 135,431,802\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 3,356,335B for [id] INT64: 830,563 values, 6,644,504B raw, 3,356,000B comp, 7 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 217,010B for [version] INT32: 830,563 values, 339,842B raw, 216,855B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 37 entries, 148B raw, 37B comp}\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,568,425B for [timestamp] INT64: 830,563 values, 4,275,187B raw, 1,568,093B comp, 7 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 109,058 entries, 872,464B raw, 109,058B comp}\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 399B for [changeset] INT64: 830,563 values, 84B raw, 98B comp, 7 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:51:56 PM INFO: o2024-05-03 20:52:02 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 116000000\n","2024-05-03 20:52:08 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 117000000\n","2024-05-03 20:52:14 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 118000000\n","2024-05-03 20:52:19 INFO  App$MultiEntitySinkObserver:116 - Entities processed: 119000000\n","rg.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 196B for [uid] INT32: 830,563 values, 48B raw, 56B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 164B for [user_sid] BINARY: 830,563 values, 48B raw, 56B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 767,669B for [tags, key] BINARY: 1,740,556 values, 2,111,088B raw, 766,776B comp, 18 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 948 entries, 16,054B raw, 948B comp}\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,371,797B for [tags, value] BINARY: 1,740,556 values, 3,129,670B raw, 1,370,225B comp, 21 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 36,967 entries, 705,405B raw, 36,967B comp}\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 10,017,962B for [nodes, index] INT32: 27,696,623 values, 40,221,502B raw, 10,013,750B comp, 108 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 2,000 entries, 8,000B raw, 2,000B comp}\n","May 3, 2024 8:51:56 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 114,589,096B for [nodes, nodeId] INT64: 27,696,623 values, 223,657,399B raw, 114,578,825B comp, 214 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: mem size 134,352,896 > 134,217,728: flushing 1,668,910 records to disk.\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 133,957,118\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 6,745,197B for [id] INT64: 1,668,910 values, 13,351,280B raw, 6,744,574B comp, 13 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 373,747B for [version] INT32: 1,668,910 values, 600,237B raw, 373,474B comp, 7 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 42 entries, 168B raw, 42B comp}\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,611,578B for [timestamp] INT64: 1,668,910 values, 10,898,376B raw, 2,610,958B comp, 13 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 93,816 entries, 750,528B raw, 93,816B comp}\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 741B for [changeset] INT64: 1,668,910 values, 156B raw, 182B comp, 13 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 343B for [uid] INT32: 1,668,910 values, 84B raw, 98B comp, 7 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 287B for [user_sid] BINARY: 1,668,910 values, 84B raw, 98B comp, 7 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,487,617B for [tags, key] BINARY: 3,972,598 values, 4,905,259B raw, 1,485,071B comp, 49 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,329 entries, 22,342B raw, 1,329B comp}\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,783,840B for [tags, value] BINARY: 3,972,598 values, 29,673,202B raw, 5,780,424B comp, 46 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 55,443 entries, 1,020,275B raw, 55,443B comp}\n","May 3, 2024 8:52:08 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 10,532,033B for [nodes, index] INT32: 25,284,457 values, 37,443,647B raw, 10,528,172B comp, 99 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 2,000 entries, 8,000B raw, 2,000B comp}\n","May 3, 2024 8:52:09 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 101,691,507B for [nodes, nodeId] INT64: 25,284,457 values, 204,903,781B raw, 101,682,100B comp, 196 pages, encodings: [PLAIN, RLE]\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 54,745,825\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 10,238,056B for [id] INT64: 2,550,609 values, 20,404,872B raw, 10,237,097B comp, 20 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 18,405B for [version] INT32: 2,550,609 values, 26,763B raw, 18,038B comp, 10 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 11 entries, 44B raw, 11B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 161,390B for [timestamp] INT64: 2,550,609 values, 186,241B raw, 160,474B comp, 20 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 20,364 entries, 162,912B raw, 20,364B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,140B for [changeset] INT64: 2,550,609 values, 240B raw, 280B comp, 20 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 490B for [uid] INT32: 2,550,609 values, 120B raw, 140B comp, 10 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 410B for [user_sid] BINARY: 2,550,609 values, 120B raw, 140B comp, 10 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 109,449B for [tags, key] BINARY: 2,669,643 values, 275,527B raw, 109,403B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 586 entries, 9,852B raw, 586B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 271,489B for [tags, value] BINARY: 2,669,643 values, 382,032B raw, 271,434B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 30,133 entries, 387,762B raw, 30,133B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 19,545,798B for [latitude] DOUBLE: 2,550,609 values, 20,404,872B raw, 19,544,839B comp, 20 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 19,534,693B for [longitude] DOUBLE: 2,550,609 values, 20,404,872B raw, 19,533,734B comp, 20 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 122,558,341\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,084,954B for [id] INT64: 2,236,938 values, 17,895,504B raw, 9,084,091B comp, 18 pages, encodings: [PLAIN, BIT_PACKED]\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 342,168B for [version] INT32: 2,236,938 values, 567,881B raw, 341,818B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 37 entries, 148B raw, 37B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,926,875B for [timestamp] INT64: 2,236,938 values, 7,490,080B raw, 1,926,024B comp, 18 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE, BIT_PACKED], dic { 125,780 entries, 1,006,240B raw, 125,780B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 1,026B for [changeset] INT64: 2,236,938 values, 216B raw, 252B comp, 18 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4412024-05-03 20:52:23 INFO  App$MultiEntitySinkObserver:123 - Total entities processed: 119381998\r\n","B for [uid] INT32: 2,236,938 values, 108B raw, 126B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\r\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 369B for [user_sid] BINARY: 2,236,938 values, 108B raw, 126B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\r\n","May 3, 2024 8:52:22 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 2,315,498B for [tags, key] BINARY: 4,183,210 values, 4,796,379B raw, 2,312,974B comp, 48 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,543 entries, 26,315B raw, 1,543B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 5,792,252B for [tags, value] BINARY: 4,183,210 values, 28,626,327B raw, 5,789,184B comp, 45 pages, encodings: [PLAIN_DICTIONARY, PLAIN, RLE], dic { 49,165 entries, 1,029,435B raw, 49,165B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 9,940,696B for [nodes, index] INT32: 22,740,893 values, 33,992,552B raw, 9,937,186B comp, 90 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 2,000 entries, 8,000B raw, 2,000B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 89,728,574B for [nodes, nodeId] INT64: 22,740,893 values, 184,701,229B raw, 89,720,079B comp, 177 pages, encodings: [PLAIN, RLE]\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.InternalParquetRecordWriter: Flushing mem columnStore to file. allocated memory: 10,864,377\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 365,420B for [id] INT64: 88,264 values, 706,112B raw, 365,373B comp, 1 pages, encodings: [PLAIN, BIT_PACKED]\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 37,587B for [version] INT32: 88,264 values, 66,802B raw, 37,548B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 217 entries, 868B raw, 217B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 137,986B for [timestamp] INT64: 88,264 values, 167,713B raw, 137,939B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 39,226 entries, 313,808B raw, 39,226B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 57B for [changeset] INT64: 88,264 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 8B raw, 1B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 49B for [uid] INT32: 88,264 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 41B for [user_sid] BINARY: 88,264 values, 12B raw, 14B comp, 1 pages, encodings: [PLAIN_DICTIONARY, RLE, BIT_PACKED], dic { 1 entries, 4B raw, 1B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 142,103B for [tags, key] BINARY: 315,064 values, 436,202B raw, 141,886B comp, 4 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 1,005 entries, 14,424B raw, 1,005B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 317,547B for [tags, value] BINARY: 315,064 values, 622,652B raw, 317,185B comp, 5 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 38,131 entries, 844,548B raw, 38,131B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 4,995,841B for [members, id] INT64: 1,217,660 values, 9,824,151B raw, 4,995,362B comp, 10 pages, encodings: [PLAIN, RLE]\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 216,493B for [members, role] BINARY: 1,217,660 values, 395,594B raw, 216,147B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 136 entries, 1,836B raw, 136B comp}\r\n","May 3, 2024 8:52:23 PM INFO: org.apache.parquet.hadoop.ColumnChunkPageWriteStore: written 92,087B for [members, type] BINARY: 1,217,660 values, 112,490B raw, 91,748B comp, 9 pages, encodings: [PLAIN_DICTIONARY, RLE], dic { 3 entries, 27B raw, 3B comp}\r\n"]}],"source":["# convert the file, it will convert osm.pbf base on three type in pbf: nodes, ways, \n","# relations, and produce three parquet files for each type\n","# for ontario-latest.osm.pbf, it only works on master node that is n2-standard-4 or higher version due to its size\n","!java -jar /geodata/osm-parquetizer-1.0.0.jar /geodata/greater-london-latest.osm.pbf\n","!java -jar /geodata/osm-parquetizer-1.0.0.jar /geodata/ile-de-france-latest.osm.pbf\n","!java -jar /geodata/osm-parquetizer-1.0.0.jar /geodata/centro-latest.osm.pbf\n","!java -jar /geodata/osm-parquetizer-1.0.0.jar /geodata/ontario-latest.osm.pbf"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: user 375 ms, sys: 78.8 ms, total: 453 ms\n","Wall time: 27.9 s\n"]}],"source":["%%time\n","# only put nodes into hdfs, not gonna use way and relations since they do not contains coordinates.\n","!hadoop fs -put /geodata/greater-london-latest.osm.pbf.node.parquet /\n","!hadoop fs -put /geodata/ile-de-france-latest.osm.pbf.node.parquet /\n","!hadoop fs -put /geodata/centro-latest.osm.pbf.node.parquet /\n","!hadoop fs -put /geodata/ontario-latest.osm.pbf.node.parquet /"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":2}